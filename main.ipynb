{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kagglehub in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (0.3.7)\n",
      "Requirement already satisfied: model-signing in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from kagglehub) (0.2.0)\n",
      "Requirement already satisfied: packaging in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from kagglehub) (24.2)\n",
      "Requirement already satisfied: requests in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from kagglehub) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from kagglehub) (4.67.1)\n",
      "Requirement already satisfied: cryptography in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from model-signing->kagglehub) (44.0.0)\n",
      "Requirement already satisfied: in-toto-attestation in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from model-signing->kagglehub) (0.9.3)\n",
      "Requirement already satisfied: sigstore in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from model-signing->kagglehub) (3.6.1)\n",
      "Requirement already satisfied: typing-extensions in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from model-signing->kagglehub) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->kagglehub) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->kagglehub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->kagglehub) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->kagglehub) (2025.1.31)\n",
      "Requirement already satisfied: cffi>=1.12 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from cryptography->model-signing->kagglehub) (1.17.1)\n",
      "Requirement already satisfied: protobuf in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from in-toto-attestation->model-signing->kagglehub) (4.23.4)\n",
      "Requirement already satisfied: id>=1.1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sigstore->model-signing->kagglehub) (1.5.0)\n",
      "Requirement already satisfied: importlib_resources~=5.7 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sigstore->model-signing->kagglehub) (5.13.0)\n",
      "Requirement already satisfied: pyasn1~=0.6 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sigstore->model-signing->kagglehub) (0.6.1)\n",
      "Requirement already satisfied: pydantic<3,>=2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sigstore->model-signing->kagglehub) (2.10.6)\n",
      "Requirement already satisfied: pyjwt>=2.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sigstore->model-signing->kagglehub) (2.10.1)\n",
      "Requirement already satisfied: pyOpenSSL>=23.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sigstore->model-signing->kagglehub) (25.0.0)\n",
      "Requirement already satisfied: rich~=13.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sigstore->model-signing->kagglehub) (13.9.4)\n",
      "Requirement already satisfied: rfc8785~=0.1.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sigstore->model-signing->kagglehub) (0.1.4)\n",
      "Requirement already satisfied: rfc3161-client~=0.1.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sigstore->model-signing->kagglehub) (0.1.2)\n",
      "Requirement already satisfied: sigstore-protobuf-specs==0.3.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sigstore->model-signing->kagglehub) (0.3.2)\n",
      "Requirement already satisfied: sigstore-rekor-types==0.0.18 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sigstore->model-signing->kagglehub) (0.0.18)\n",
      "Requirement already satisfied: tuf~=5.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sigstore->model-signing->kagglehub) (5.1.0)\n",
      "Requirement already satisfied: platformdirs~=4.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sigstore->model-signing->kagglehub) (4.3.6)\n",
      "Requirement already satisfied: betterproto==2.0.0b6 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sigstore-protobuf-specs==0.3.2->sigstore->model-signing->kagglehub) (2.0.0b6)\n",
      "Requirement already satisfied: grpclib<0.5.0,>=0.4.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from betterproto==2.0.0b6->sigstore-protobuf-specs==0.3.2->sigstore->model-signing->kagglehub) (0.4.7)\n",
      "Requirement already satisfied: python-dateutil<3.0,>=2.8 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from betterproto==2.0.0b6->sigstore-protobuf-specs==0.3.2->sigstore->model-signing->kagglehub) (2.9.0.post0)\n",
      "Requirement already satisfied: pycparser in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from cffi>=1.12->cryptography->model-signing->kagglehub) (2.22)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pydantic<3,>=2->sigstore->model-signing->kagglehub) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pydantic<3,>=2->sigstore->model-signing->kagglehub) (2.27.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from rich~=13.0->sigstore->model-signing->kagglehub) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from rich~=13.0->sigstore->model-signing->kagglehub) (2.19.1)\n",
      "Requirement already satisfied: securesystemslib~=1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tuf~=5.0->sigstore->model-signing->kagglehub) (1.2.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich~=13.0->sigstore->model-signing->kagglehub) (0.1.2)\n",
      "Requirement already satisfied: email-validator>=2.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pydantic[email]<3,>=2->sigstore-rekor-types==0.0.18->sigstore->model-signing->kagglehub) (2.2.0)\n",
      "Requirement already satisfied: dnspython>=2.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from email-validator>=2.0.0->pydantic[email]<3,>=2->sigstore-rekor-types==0.0.18->sigstore->model-signing->kagglehub) (2.7.0)\n",
      "Requirement already satisfied: h2<5,>=3.1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from grpclib<0.5.0,>=0.4.1->betterproto==2.0.0b6->sigstore-protobuf-specs==0.3.2->sigstore->model-signing->kagglehub) (4.2.0)\n",
      "Requirement already satisfied: multidict in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from grpclib<0.5.0,>=0.4.1->betterproto==2.0.0b6->sigstore-protobuf-specs==0.3.2->sigstore->model-signing->kagglehub) (6.1.0)\n",
      "Requirement already satisfied: six>=1.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from python-dateutil<3.0,>=2.8->betterproto==2.0.0b6->sigstore-protobuf-specs==0.3.2->sigstore->model-signing->kagglehub) (1.17.0)\n",
      "Requirement already satisfied: hyperframe<7,>=6.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from h2<5,>=3.1.0->grpclib<0.5.0,>=0.4.1->betterproto==2.0.0b6->sigstore-protobuf-specs==0.3.2->sigstore->model-signing->kagglehub) (6.1.0)\n",
      "Requirement already satisfied: hpack<5,>=4.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from h2<5,>=3.1.0->grpclib<0.5.0,>=0.4.1->betterproto==2.0.0b6->sigstore-protobuf-specs==0.3.2->sigstore->model-signing->kagglehub) (4.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /teamspace/studios/this_studio/.cache/kagglehub/datasets/mariaherrerot/aptos2019/versions/3\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"mariaherrerot/aptos2019\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (0.21.0)\n",
      "Requirement already satisfied: numpy in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: torch==2.6.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torchvision) (2.6.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torchvision) (11.1.0)\n",
      "Requirement already satisfied: filelock in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch==2.6.0->torchvision) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch==2.6.0->torchvision) (4.12.2)\n",
      "Requirement already satisfied: networkx in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch==2.6.0->torchvision) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch==2.6.0->torchvision) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch==2.6.0->torchvision) (2025.2.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch==2.6.0->torchvision) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch==2.6.0->torchvision) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch==2.6.0->torchvision) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch==2.6.0->torchvision) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch==2.6.0->torchvision) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch==2.6.0->torchvision) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch==2.6.0->torchvision) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch==2.6.0->torchvision) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch==2.6.0->torchvision) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch==2.6.0->torchvision) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch==2.6.0->torchvision) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch==2.6.0->torchvision) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch==2.6.0->torchvision) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch==2.6.0->torchvision) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch==2.6.0->torchvision) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sympy==1.13.1->torch==2.6.0->torchvision) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jinja2->torch==2.6.0->torchvision) (3.0.2)\n",
      "Requirement already satisfied: opencv-python in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (4.11.0.86)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from opencv-python) (1.26.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision --upgrade\n",
    "# # # or for conda users:\n",
    "# # conda update torchvision -c pytorch\n",
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torch.nn import SyncBatchNorm\n",
    "from torch.nn.parallel import DataParallel\n",
    "import torchvision.transforms.functional as TF\n",
    "from PIL import Image\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "CPU: 32\n",
      "GPU: 1\n"
     ]
    }
   ],
   "source": [
    "# =================================================================\n",
    "# STEP 1: PATHS TO CONFIGURE (UPDATE THESE!)\n",
    "# =================================================================\n",
    "# CSV paths\n",
    "\n",
    "TRAIN_CSV = \"/teamspace/studios/this_studio/.cache/kagglehub/datasets/mariaherrerot/aptos2019/versions/3/train_1.csv\"         # CSV with training image names (id_code column)\n",
    "VAL_CSV = \"/teamspace/studios/this_studio/.cache/kagglehub/datasets/mariaherrerot/aptos2019/versions/3/valid.csv\"      # CSV with validation image names\n",
    "TEST_CSV = \"/teamspace/studios/this_studio/.cache/kagglehub/datasets/mariaherrerot/aptos2019/versions/3/test.csv\"           # CSV with test image names\n",
    "\n",
    "# Image directories\n",
    "TRAIN_IMG_DIR = \"/teamspace/studios/this_studio/.cache/kagglehub/datasets/mariaherrerot/aptos2019/versions/3/train_images/train_images\"         # Folder with training images\n",
    "VAL_IMG_DIR = \"/teamspace/studios/this_studio/.cache/kagglehub/datasets/mariaherrerot/aptos2019/versions/3/val_images/val_images\"      # Folder with validation images\n",
    "TEST_IMG_DIR = \"/teamspace/studios/this_studio/.cache/kagglehub/datasets/mariaherrerot/aptos2019/versions/3/test_images/test_images\"           # Folder with test images\n",
    "\n",
    "OUTPUT_DIR = \"/teamspace/studios/this_studio/generated_hr_output\"     # Where HR images will be saved\n",
    "# =================================================================\n",
    "\n",
    "# Hyperparameters\n",
    "BATCH_SIZE = 32                                        # Increased for multi-GPU\n",
    "LR_SIZE = 64                                           # Low-res input size\n",
    "HR_SIZE = 128                                          # High-res target size\n",
    "EPOCHS = 500                                           # Number of epochs\n",
    "NUM_GPUS = torch.cuda.device_count()                   # Number of available GPUs\n",
    "\n",
    "# Initialize multi-GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.backends.cudnn.benchmark = True  # Optimizes for fixed input size\n",
    "print(device)\n",
    "print(\"CPU:\", os.cpu_count())\n",
    "print(\"GPU:\", NUM_GPUS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset Class\n",
    "# Optimized Custom Dataset Class\n",
    "class FundusDataset(Dataset):\n",
    "    def __init__(self, csv_path, img_dir):\n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        self.img_paths = [os.path.join(img_dir, f\"{img_id}.png\") for img_id in self.df[\"id_code\"]]\n",
    "        print(f\"Loaded dataset with {len(self.df)} samples from {img_dir}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.img_paths[idx]\n",
    "\n",
    "        # Check if file exists before loading\n",
    "        if not os.path.exists(img_path):\n",
    "            print(f\"Warning: Missing file {img_path}\")\n",
    "            return torch.zeros(3, LR_SIZE, LR_SIZE), torch.zeros(3, HR_SIZE, HR_SIZE)\n",
    "\n",
    "        # Load image using OpenCV (faster than PIL)\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert from BGR to RGB\n",
    "\n",
    "        # Resize images efficiently\n",
    "        lr_image = cv2.resize(image, (LR_SIZE, LR_SIZE), interpolation=cv2.INTER_CUBIC)\n",
    "        hr_image = cv2.resize(image, (HR_SIZE, HR_SIZE), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "        # Convert to tensor & normalize\n",
    "        lr_tensor = TF.to_tensor(lr_image)\n",
    "        hr_tensor = TF.to_tensor(hr_image)\n",
    "\n",
    "        lr_tensor = TF.normalize(lr_tensor, mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "        hr_tensor = TF.normalize(hr_tensor, mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "\n",
    "        return lr_tensor, hr_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator with Multi-GPU Support\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 9, padding=4), nn.PReLU(),\n",
    "            *[ResidualBlock(64) for _ in range(16)],\n",
    "            nn.Conv2d(64, 64, 3, padding=1), SyncBatchNorm(64),\n",
    "            nn.Conv2d(64, 256, 3, padding=1), nn.PixelShuffle(2), nn.PReLU(),\n",
    "            nn.Conv2d(64, 3, 9, padding=4), nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.main(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(channels, channels, 3, padding=1),\n",
    "            nn.BatchNorm2d(channels),\n",
    "            nn.PReLU(),\n",
    "            nn.Conv2d(channels, channels, 3, padding=1),\n",
    "            nn.BatchNorm2d(channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimized Discriminator with SyncBatchNorm\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3, stride=1, padding=1), nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(64, 64, 3, stride=2, padding=1), nn.SyncBatchNorm(64), nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(64, 128, 3, stride=1, padding=1), nn.SyncBatchNorm(128), nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(128, 128, 3, stride=2, padding=1), nn.SyncBatchNorm(128), nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(128, 256, 3, stride=1, padding=1), nn.SyncBatchNorm(256), nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(256, 256, 3, stride=2, padding=1), nn.SyncBatchNorm(256), nn.LeakyReLU(0.2),\n",
    "            nn.AdaptiveAvgPool2d(1), nn.Conv2d(256, 512, 1), nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(512, 1, 1), nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.main(x).view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gan():\n",
    "    # Initialize datasets\n",
    "    train_dataset = FundusDataset(TRAIN_CSV, TRAIN_IMG_DIR)\n",
    "    val_dataset = FundusDataset(VAL_CSV, VAL_IMG_DIR)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE,\n",
    "                              shuffle=True, num_workers=os.cpu_count(), pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE,\n",
    "                            num_workers=os.cpu_count(), pin_memory=True)\n",
    "\n",
    "    # Initialize models with DataParallel\n",
    "    G = DataParallel(Generator().to(device), device_ids=range(NUM_GPUS))\n",
    "    D = DataParallel(Discriminator().to(device), device_ids=range(NUM_GPUS))\n",
    "\n",
    "    opt_G = optim.Adam(G.parameters(), lr=1e-4)\n",
    "    opt_D = optim.Adam(D.parameters(), lr=1e-4)\n",
    "\n",
    "    # Loss functions\n",
    "    criterion_mse = nn.MSELoss()\n",
    "    criterion_bce = nn.BCEWithLogitsLoss()\n",
    "    vgg = nn.Sequential(*list(torch.hub.load('pytorch/vision', 'vgg19', pretrained=True).features)[:35])\n",
    "    vgg = DataParallel(vgg.to(device), device_ids=range(NUM_GPUS)).eval()\n",
    "\n",
    "    scaler = torch.amp.GradScaler()  # Mixed Precision for speedup\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    print(f\"\\nStarting training on {NUM_GPUS} GPUs with batch size {BATCH_SIZE}\")\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        start_time = time.time()\n",
    "        G.train()\n",
    "        D.train()\n",
    "\n",
    "        # Training loop\n",
    "        for batch_idx, (lr, hr) in enumerate(train_loader):\n",
    "            lr, hr = lr.to(device, non_blocking=True), hr.to(device, non_blocking=True)\n",
    "\n",
    "            # Train Discriminator\n",
    "            with torch.amp.autocast(device_type=\"cuda\"):\n",
    "                real_preds = D(hr)\n",
    "                real_loss = criterion_bce(real_preds, torch.ones_like(real_preds))\n",
    "\n",
    "                fake_hr = G(lr)\n",
    "                fake_preds = D(fake_hr.detach())\n",
    "                fake_loss = criterion_bce(fake_preds, torch.zeros_like(fake_preds))\n",
    "\n",
    "                loss_D = (real_loss + fake_loss) / 2\n",
    "\n",
    "            scaler.scale(loss_D).backward()\n",
    "            scaler.step(opt_D)  # Step before zero_grad\n",
    "            opt_D.zero_grad(set_to_none=True)\n",
    "\n",
    "            # Train Generator\n",
    "            with torch.amp.autocast(device_type=\"cuda\"):\n",
    "                fake_preds = D(fake_hr)\n",
    "                loss_G_adv = criterion_bce(fake_preds, torch.ones_like(fake_preds))\n",
    "                loss_G_mse = criterion_mse(fake_hr, hr)\n",
    "                loss_G_percep = criterion_mse(vgg(fake_hr), vgg(hr))\n",
    "                loss_G = loss_G_adv + 0.001 * loss_G_percep + 0.006 * loss_G_mse\n",
    "\n",
    "            scaler.scale(loss_G).backward()\n",
    "            scaler.step(opt_G)\n",
    "            opt_G.zero_grad(set_to_none=True)\n",
    "            scaler.update()\n",
    "\n",
    "            if batch_idx % 100 == 0:\n",
    "                print(f\"Epoch {epoch+1} | Batch {batch_idx}/{len(train_loader)} | \"\n",
    "                      f\"D Loss: {loss_D.item():.4f} | G Loss: {loss_G.item():.4f}\")\n",
    "\n",
    "        # Validation\n",
    "        G.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for lr_val, hr_val in val_loader:\n",
    "                lr_val = lr_val.to(device, non_blocking=True)\n",
    "                hr_val = hr_val.to(device, non_blocking=True)\n",
    "                fake_hr_val = G(lr_val)\n",
    "                val_loss += criterion_mse(fake_hr_val, hr_val).item()\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        epoch_time = time.time() - start_time\n",
    "\n",
    "        # Save best model\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            traced_G = torch.jit.trace(G.module, torch.randn(1, 3, LR_SIZE, LR_SIZE, device=device))\n",
    "            traced_G.save(\"best_generator.pth\")\n",
    "            print(f\"New best model saved with val loss: {val_loss:.4f}\")\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{EPOCHS} completed in {epoch_time:.2f}s | \"\n",
    "              f\"Val Loss: {val_loss:.4f} | GPU Mem: {torch.cuda.memory_allocated()/1e9:.2f}GB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_hr_images():\n",
    "    G = Generator().to(device)\n",
    "    \n",
    "    # Load checkpoint\n",
    "    checkpoint = torch.load(\"best_generator.pth\", map_location=device, weights_only=False)\n",
    "    \n",
    "    # Diagnostic print to understand checkpoint structure\n",
    "    print(f\"Checkpoint type: {type(checkpoint)}\")\n",
    "    \n",
    "    # Attempt multiple extraction strategies\n",
    "    try:\n",
    "        # Strategy 1: Direct state dict extraction if it's a scripted module\n",
    "        if hasattr(checkpoint, '_actual_script_module'):\n",
    "            state_dict = checkpoint._actual_script_module.state_dict()\n",
    "        # Strategy 2: Try getting state dict directly\n",
    "        elif hasattr(checkpoint, 'state_dict'):\n",
    "            state_dict = checkpoint.state_dict()\n",
    "        # Strategy 3: Assume dictionary-like structure\n",
    "        else:\n",
    "            state_dict = checkpoint.get('state_dict', checkpoint)\n",
    "        \n",
    "        # Clean state dict keys\n",
    "        new_state_dict = {}\n",
    "        for k, v in state_dict.items():\n",
    "            clean_key = k[7:] if k.startswith('module.') else k\n",
    "            new_state_dict[clean_key] = v\n",
    "        \n",
    "        # Load cleaned state dict\n",
    "        G.load_state_dict(new_state_dict)\n",
    "        G.eval()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting state dict: {e}\")\n",
    "        # If all else fails, you might need to manually inspect the checkpoint\n",
    "        raise\n",
    "\n",
    "    # Load test dataset\n",
    "    test_dataset = FundusDataset(TEST_CSV, TEST_IMG_DIR)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE*2, \n",
    "                            num_workers=os.cpu_count(), pin_memory=True)\n",
    "    \n",
    "    print(f\"\\nGenerating HR images for {len(test_dataset)} test samples...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (lr, _) in enumerate(test_loader):\n",
    "            lr = lr.to(device, non_blocking=True)\n",
    "            fake_hr = G(lr)\n",
    "            fake_hr = (fake_hr * 0.5 + 0.5).clamp(0, 1)  # Denormalize\n",
    "            \n",
    "            for img_idx in range(fake_hr.size(0)):\n",
    "                img_name = test_dataset.df.iloc[batch_idx*BATCH_SIZE + img_idx]['id_code'] + \"_hr.png\"\n",
    "                img_path = os.path.join(OUTPUT_DIR, img_name)\n",
    "                transforms.ToPILImage()(fake_hr[img_idx].cpu()).save(img_path)\n",
    "            \n",
    "            print(f\"Generated batch {batch_idx+1}/{len(test_loader)}\")\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"Generation completed in {total_time:.2f}s | Output: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset with 2930 samples from /teamspace/studios/this_studio/.cache/kagglehub/datasets/mariaherrerot/aptos2019/versions/3/train_images/train_images\n",
      "Loaded dataset with 366 samples from /teamspace/studios/this_studio/.cache/kagglehub/datasets/mariaherrerot/aptos2019/versions/3/val_images/val_images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/pytorch/vision/zipball/main\" to /home/zeus/.cache/torch/hub/main.zip\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to /home/zeus/.cache/torch/hub/checkpoints/vgg19-dcbb9e9d.pth\n",
      "100%|██████████| 548M/548M [00:01<00:00, 317MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training on 1 GPUs with batch size 32\n",
      "Epoch 1 | Batch 0/92 | D Loss: 0.7237 | G Loss: 0.4960\n",
      "New best model saved with val loss: 0.0764\n",
      "Epoch 1/500 completed in 32.30s | Val Loss: 0.0764 | GPU Mem: 0.22GB\n",
      "Epoch 2 | Batch 0/92 | D Loss: 0.8052 | G Loss: 0.3260\n",
      "New best model saved with val loss: 0.0459\n",
      "Epoch 2/500 completed in 28.05s | Val Loss: 0.0459 | GPU Mem: 0.22GB\n",
      "Epoch 3 | Batch 0/92 | D Loss: 0.8096 | G Loss: 0.3193\n",
      "New best model saved with val loss: 0.0156\n",
      "Epoch 3/500 completed in 27.50s | Val Loss: 0.0156 | GPU Mem: 0.22GB\n",
      "Epoch 4 | Batch 0/92 | D Loss: 0.8117 | G Loss: 0.3164\n",
      "New best model saved with val loss: 0.0127\n",
      "Epoch 4/500 completed in 27.72s | Val Loss: 0.0127 | GPU Mem: 0.22GB\n",
      "Epoch 5 | Batch 0/92 | D Loss: 0.8123 | G Loss: 0.3155\n",
      "New best model saved with val loss: 0.0123\n",
      "Epoch 5/500 completed in 27.61s | Val Loss: 0.0123 | GPU Mem: 0.22GB\n",
      "Epoch 6 | Batch 0/92 | D Loss: 0.8126 | G Loss: 0.3150\n",
      "New best model saved with val loss: 0.0111\n",
      "Epoch 6/500 completed in 27.56s | Val Loss: 0.0111 | GPU Mem: 0.22GB\n",
      "Epoch 7 | Batch 0/92 | D Loss: 0.8128 | G Loss: 0.3148\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m     torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mmemory_allocated()\n\u001b[1;32m      4\u001b[0m     torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mmemory_reserved()\n\u001b[0;32m----> 6\u001b[0m \u001b[43mtrain_gan\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m generate_hr_images()\n",
      "Cell \u001b[0;32mIn[11], line 62\u001b[0m, in \u001b[0;36mtrain_gan\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m     loss_G \u001b[38;5;241m=\u001b[39m loss_G_adv \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.001\u001b[39m \u001b[38;5;241m*\u001b[39m loss_G_percep \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.006\u001b[39m \u001b[38;5;241m*\u001b[39m loss_G_mse\n\u001b[1;32m     61\u001b[0m scaler\u001b[38;5;241m.\u001b[39mscale(loss_G)\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 62\u001b[0m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopt_G\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m opt_G\u001b[38;5;241m.\u001b[39mzero_grad(set_to_none\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     64\u001b[0m scaler\u001b[38;5;241m.\u001b[39mupdate()\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/amp/grad_scaler.py:457\u001b[0m, in \u001b[0;36mGradScaler.step\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munscale_(optimizer)\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m    454\u001b[0m     \u001b[38;5;28mlen\u001b[39m(optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    455\u001b[0m ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo inf checks were recorded for this optimizer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 457\u001b[0m retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_opt_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    459\u001b[0m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstage\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m OptState\u001b[38;5;241m.\u001b[39mSTEPPED\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/amp/grad_scaler.py:351\u001b[0m, in \u001b[0;36mGradScaler._maybe_opt_step\u001b[0;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_maybe_opt_step\u001b[39m(\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    345\u001b[0m     optimizer: torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mOptimizer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    349\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[1;32m    350\u001b[0m     retval: Optional[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 351\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf_per_device\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    352\u001b[0m         retval \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    353\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/amp/grad_scaler.py:351\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_maybe_opt_step\u001b[39m(\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    345\u001b[0m     optimizer: torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mOptimizer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    349\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[1;32m    350\u001b[0m     retval: Optional[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 351\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28msum\u001b[39m(\u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    352\u001b[0m         retval \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    353\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    with torch.no_grad():\n",
    "        torch.cuda.memory_allocated()\n",
    "        torch.cuda.memory_reserved()\n",
    "\n",
    "    train_gan()\n",
    "    generate_hr_images()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
